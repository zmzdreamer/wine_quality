{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "552fdffd-a7ba-40b9-a3f5-35dd2a6e4f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e000ae30-9e20-44fe-b533-53a247e40e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¦‚æœä½¿ç”¨ xgboost\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    has_xgb = True\n",
    "except Exception:\n",
    "    has_xgb = False\n",
    "    print(\"æœªæ£€æµ‹åˆ° xgboostï¼Œè‹¥éœ€ä½¿ç”¨è¯·å®‰è£…ï¼špip install xgboost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27549fdc-0d76-475d-b1d1-c51b17c648e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- é…ç½® ----------\n",
    "DATA_PATH = \"E:/ML/wine_quality/data/winequality-red.csv\"  # æ”¹æˆä½ çš„è·¯å¾„\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "os.makedirs(\"results/figures\", exist_ok=True)\n",
    "os.makedirs(\"results/metrics\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da26e8b0-9138-4554-a6c1-b4feccec3c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ•°æ®å½¢çŠ¶: (1599, 12)\n",
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n"
     ]
    }
   ],
   "source": [
    "# ---------- 1. åŠ è½½æ•°æ® ----------\n",
    "df = pd.read_csv(DATA_PATH, sep=';')  # UCI è‘¡è„é…’æ•°æ®é›†é€šå¸¸åˆ†å·åˆ†éš”\n",
    "print(\"æ•°æ®å½¢çŠ¶:\", df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd12f008-eea1-4e67-a83b-72f7cde5b90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
      "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
      "mean        8.319637          0.527821     0.270976        2.538806   \n",
      "std         1.741096          0.179060     0.194801        1.409928   \n",
      "min         4.600000          0.120000     0.000000        0.900000   \n",
      "25%         7.100000          0.390000     0.090000        1.900000   \n",
      "50%         7.900000          0.520000     0.260000        2.200000   \n",
      "75%         9.200000          0.640000     0.420000        2.600000   \n",
      "max        15.900000          1.580000     1.000000       15.500000   \n",
      "\n",
      "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
      "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
      "mean      0.087467            15.874922             46.467792     0.996747   \n",
      "std       0.047065            10.460157             32.895324     0.001887   \n",
      "min       0.012000             1.000000              6.000000     0.990070   \n",
      "25%       0.070000             7.000000             22.000000     0.995600   \n",
      "50%       0.079000            14.000000             38.000000     0.996750   \n",
      "75%       0.090000            21.000000             62.000000     0.997835   \n",
      "max       0.611000            72.000000            289.000000     1.003690   \n",
      "\n",
      "                pH    sulphates      alcohol      quality  \n",
      "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
      "mean      3.311113     0.658149    10.422983     5.636023  \n",
      "std       0.154386     0.169507     1.065668     0.807569  \n",
      "min       2.740000     0.330000     8.400000     3.000000  \n",
      "25%       3.210000     0.550000     9.500000     5.000000  \n",
      "50%       3.310000     0.620000    10.200000     6.000000  \n",
      "75%       3.400000     0.730000    11.100000     6.000000  \n",
      "max       4.010000     2.000000    14.900000     8.000000  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------- 2. åˆæ­¥å¯è§†åŒ–ï¼ˆåˆ†å¸ƒ & ç›¸å…³æ€§ï¼‰ ----------\n",
    "# åŸºæœ¬ç»Ÿè®¡\n",
    "print(df.describe())\n",
    "\n",
    "# ç›®æ ‡åˆ†å¸ƒ\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(df['quality'], bins=range(int(df['quality'].min()), int(df['quality'].max())+2), rwidth=0.8)\n",
    "plt.xlabel(\"quality\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.title(\"Quality distribution\")\n",
    "plt.savefig(\"results/figures/quality_distribution.png\", bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# ç›¸å…³çŸ©é˜µçƒ­åŠ›å›¾ï¼ˆä½¿ç”¨ pandasï¼‰\n",
    "corr = df.corr()\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.matshow(corr)\n",
    "plt.colorbar()\n",
    "plt.title(\"Correlation matrix (visual)\", y=1.2)\n",
    "plt.savefig(\"results/figures/correlation_matrix.png\", bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb7f46b9-332c-42b2-a42f-5fadb5524c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç¼ºå¤±å€¼ç»Ÿè®¡ï¼š\n",
      " fixed acidity           0\n",
      "volatile acidity        0\n",
      "citric acid             0\n",
      "residual sugar          0\n",
      "chlorides               0\n",
      "free sulfur dioxide     0\n",
      "total sulfur dioxide    0\n",
      "density                 0\n",
      "pH                      0\n",
      "sulphates               0\n",
      "alcohol                 0\n",
      "quality                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ---------- 3. å¤„ç†ç¼ºå¤±å€¼ ----------\n",
    "# æ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±\n",
    "print(\"ç¼ºå¤±å€¼ç»Ÿè®¡ï¼š\\n\", df.isnull().sum())\n",
    "# ç¤ºä¾‹ç­–ç•¥ï¼šå¦‚æœæœ‰å°‘é‡ç¼ºå¤±ç”¨ä¸­ä½æ•°å¡«å……ï¼›å¦‚æœå¾ˆå¤šå¯è€ƒè™‘åˆ é™¤åˆ—/è¡Œ\n",
    "df = df.fillna(df.median())  # ç®€å•çš„ä¸­ä½æ•°å¡«å……"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1bacf2a-17be-4b41-8128-b7f6e8539416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:/ML/wine_quality/results/scaler.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------- 4. ç‰¹å¾ä¸ç›®æ ‡åˆ†ç¦» ----------\n",
    "X = df.drop(columns=['quality'])\n",
    "y = df['quality']\n",
    "\n",
    "# 9/29ï¼šåšç‰¹å¾ç¼©æ”¾ï¼ˆStandardScalerï¼‰\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ä¿å­˜ scaler ä»¥å¤‡åç”¨\n",
    "joblib.dump(scaler, \"E:/ML/wine_quality/results/scaler.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1d1ba57-f82b-4184-97c7-da4903e3dfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒé›†å¤§å°: (1279, 11) æµ‹è¯•é›†å¤§å°: (320, 11)\n"
     ]
    }
   ],
   "source": [
    "# ---------- 5. åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›† ----------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "print(\"è®­ç»ƒé›†å¤§å°:\", X_train.shape, \"æµ‹è¯•é›†å¤§å°:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "817721a7-7a2f-458a-97c1-b552428e6892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression -> RMSE: 0.6245, MAE: 0.5035, R2: 0.4032\n"
     ]
    }
   ],
   "source": [
    "# ---------- 6. è®­ç»ƒ Baselineï¼šLinear Regression ----------\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "def evaluate_model(y_true, y_pred, prefix=\"model\"):\n",
    "    # å…¼å®¹æ—§ç‰ˆæœ¬scikit-learnï¼šä½¿ç”¨np.sqrtè®¡ç®—RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"{prefix} -> RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}\")\n",
    "    return {\"rmse\": rmse, \"mae\": mae, \"r2\": r2}\n",
    "\n",
    "metrics_lr = evaluate_model(y_test, y_pred_lr, prefix=\"LinearRegression\")\n",
    "joblib.dump(lr, \"results/lr_model.joblib\")\n",
    "\n",
    "# ä¿å­˜æ®‹å·®å›¾ï¼ˆé¢„æµ‹ vs çœŸå®ï¼‰\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_test, y_pred_lr, alpha=0.6)\n",
    "plt.xlabel(\"True quality\")\n",
    "plt.ylabel(\"Predicted quality\")\n",
    "plt.title(\"LinearRegression: Pred vs True\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--')\n",
    "plt.savefig(\"results/figures/pred_vs_true_lr.png\", bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbf3185a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest -> RMSE: 0.5490, MAE: 0.4220, R2: 0.5389\n",
      "                 feature  importance\n",
      "10               alcohol    0.270868\n",
      "9              sulphates    0.148406\n",
      "1       volatile acidity    0.111547\n",
      "6   total sulfur dioxide    0.076786\n",
      "4              chlorides    0.071132\n",
      "8                     pH    0.061418\n",
      "3         residual sugar    0.057892\n",
      "0          fixed acidity    0.053186\n",
      "7                density    0.050816\n",
      "2            citric acid    0.050752\n",
      "5    free sulfur dioxide    0.047197\n"
     ]
    }
   ],
   "source": [
    "# ---------- 7. è®­ç»ƒ RandomForest ----------\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "metrics_rf = evaluate_model(y_test, y_pred_rf, prefix=\"RandomForest\")\n",
    "joblib.dump(rf, \"results/rf_model.joblib\")\n",
    "\n",
    "# ç‰¹å¾é‡è¦æ€§ï¼ˆåŸå§‹ç‰¹å¾åï¼‰\n",
    "feat_importances = rf.feature_importances_\n",
    "feat_names = X.columns\n",
    "fi_df = pd.DataFrame({\"feature\": feat_names, \"importance\": feat_importances}).sort_values(by=\"importance\", ascending=False)\n",
    "fi_df.to_csv(\"results/metrics/rf_feature_importance.csv\", index=False)\n",
    "print(fi_df)\n",
    "\n",
    "# ç»˜å›¾\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.barh(fi_df['feature'][::-1], fi_df['importance'][::-1])\n",
    "plt.xlabel(\"importance\")\n",
    "plt.title(\"Random Forest Feature Importance\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"results/figures/rf_feature_importance.png\", bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a65bdfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest 5-fold CV RMSE (negated): [-0.5608264  -0.59628485 -0.59896917 -0.5820473  -0.54495147]\n",
      "å¹³å‡ CV RMSE: 0.5766158373223337\n"
     ]
    }
   ],
   "source": [
    "# ---------- 8. äº¤å‰éªŒè¯ï¼ˆKFoldï¼‰ç¤ºä¾‹ ----------\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "cv_scores = cross_val_score(rf, X_scaled, y, cv=kf, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "print(\"RandomForest 5-fold CV RMSE (negated):\", cv_scores)\n",
    "print(\"å¹³å‡ CV RMSE:\", -np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792a923a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost -> RMSE: 0.5927, MAE: 0.4175, R2: 0.4625\n"
     ]
    }
   ],
   "source": [
    "# ---------- 9. XGBoost è®­ç»ƒä¸äº¤å‰éªŒè¯ï¼ˆå¦‚æœå®‰è£…äº† xgboostï¼‰ ----------\n",
    "if has_xgb:\n",
    "    # åŸå§‹XGBoostï¼ˆé»˜è®¤å‚æ•°ï¼‰\n",
    "    print(\"=== è®­ç»ƒåŸå§‹XGBoostæ¨¡å‹ ===\")\n",
    "    xgbr_default = xgb.XGBRegressor(objective='reg:squarederror', random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    xgbr_default.fit(X_train, y_train)\n",
    "    y_pred_xgb_default = xgbr_default.predict(X_test)\n",
    "    metrics_xgb_default = evaluate_model(y_test, y_pred_xgb_default, prefix=\"XGBoost (é»˜è®¤å‚æ•°)\")\n",
    "    \n",
    "    # è°ƒä¼˜åçš„XGBoostï¼ˆé’ˆå¯¹å°æ•°æ®é›†ä¼˜åŒ–ï¼‰\n",
    "    print(\"\\n=== è®­ç»ƒè°ƒä¼˜XGBoostæ¨¡å‹ ===\")\n",
    "    xgbr_tuned = xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        n_estimators=50,           # å‡å°‘æ ‘çš„æ•°é‡é˜²æ­¢è¿‡æ‹Ÿåˆ\n",
    "        max_depth=4,               # é™åˆ¶æ·±åº¦\n",
    "        learning_rate=0.1,         # å­¦ä¹ ç‡\n",
    "        subsample=0.8,             # å­é‡‡æ ·\n",
    "        colsample_bytree=0.8,      # ç‰¹å¾é‡‡æ ·\n",
    "        reg_alpha=0.1,             # L1æ­£åˆ™åŒ–\n",
    "        reg_lambda=1.0,            # L2æ­£åˆ™åŒ–\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    xgbr_tuned.fit(X_train, y_train)\n",
    "    y_pred_xgb_tuned = xgbr_tuned.predict(X_test)\n",
    "    metrics_xgb_tuned = evaluate_model(y_test, y_pred_xgb_tuned, prefix=\"XGBoost (è°ƒä¼˜å‚æ•°)\")\n",
    "    \n",
    "    # ä½¿ç”¨è°ƒä¼˜åçš„æ¨¡å‹ä½œä¸ºæœ€ç»ˆç»“æœ\n",
    "    metrics_xgb = metrics_xgb_tuned\n",
    "    y_pred_xgb = y_pred_xgb_tuned\n",
    "    \n",
    "    # ä¿å­˜æ¨¡å‹\n",
    "    joblib.dump(xgbr_tuned, \"results/xgb_model_tuned.joblib\")\n",
    "    \n",
    "    # XGBoostç‰¹å¾é‡è¦æ€§åˆ†æ\n",
    "    print(\"\\n=== XGBoostç‰¹å¾é‡è¦æ€§ ===\")\n",
    "    feature_names = df.drop(columns=['quality']).columns\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': xgbr_tuned.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    print(importance_df)\n",
    "    \n",
    "    # XGBoostäº¤å‰éªŒè¯\n",
    "    print(\"\\n=== XGBoost 5æŠ˜äº¤å‰éªŒè¯ ===\")\n",
    "    xgb_cv_scores = cross_val_score(xgbr_tuned, X_scaled, y, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "    print(f\"XGBoost CV RMSE scores: {xgb_cv_scores}\")\n",
    "    print(f\"å¹³å‡ CV RMSE: {-np.mean(xgb_cv_scores):.4f}\")\n",
    "    \n",
    "else:\n",
    "    metrics_xgb = None\n",
    "    print(\"XGBoostæœªå®‰è£…ï¼Œè·³è¿‡è®­ç»ƒ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc6bd9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "GridSearch æœ€ä½³å‚æ•°ï¼š {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RF (GridSearch best) -> RMSE: 0.5490, MAE: 0.4220, R2: 0.5389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['results/rf_gridsearch.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------- 10. GridSearchCV ç¤ºä¾‹ï¼ˆå¯¹ RandomForest è°ƒå‚ï¼Œä½œä¸º 10/4 çš„å·¥ä½œèµ·ç‚¹ï¼‰ ----------\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 8, 12],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "gsearch = GridSearchCV(RandomForestRegressor(random_state=RANDOM_STATE, n_jobs=-1),\n",
    "                       param_grid, cv=3, scoring='neg_root_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "gsearch.fit(X_train, y_train)\n",
    "print(\"GridSearch æœ€ä½³å‚æ•°ï¼š\", gsearch.best_params_)\n",
    "best_rf = gsearch.best_estimator_\n",
    "y_pred_best_rf = best_rf.predict(X_test)\n",
    "metrics_best_rf = evaluate_model(y_test, y_pred_best_rf, prefix=\"RF (GridSearch best)\")\n",
    "joblib.dump(gsearch, \"results/rf_gridsearch.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bca60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å·²ä¿å­˜ model_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "# ---------- 11. ä¿å­˜æœ€ç»ˆè¯„ä¼°è¡¨ï¼ˆåŒ…å«è¯¦ç»†æŒ‡æ ‡è§£é‡Šï¼‰ ----------\n",
    "results_summary = {\n",
    "    \"LinearRegression\": metrics_lr,\n",
    "    \"RandomForest\": metrics_rf,\n",
    "    \"RandomForest_GridSearch\": metrics_best_rf,\n",
    "    \"XGBoost\": metrics_xgb\n",
    "}\n",
    "\n",
    "# åˆ›å»ºè¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Š\n",
    "print(\"=== æ¨¡å‹æ€§èƒ½è¯¦ç»†å¯¹æ¯” ===\")\n",
    "print(\"æŒ‡æ ‡è¯´æ˜ï¼š\")\n",
    "print(\"- RMSE: å‡æ–¹æ ¹è¯¯å·®ï¼Œè¶Šå°è¶Šå¥½ï¼Œå•ä½ä¸ç›®æ ‡å˜é‡ç›¸åŒ\")\n",
    "print(\"- MAE: å¹³å‡ç»å¯¹è¯¯å·®ï¼Œè¶Šå°è¶Šå¥½ï¼Œå¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿ\")\n",
    "print(\"- RÂ²: å†³å®šç³»æ•°ï¼Œè¶Šæ¥è¿‘1è¶Šå¥½ï¼Œè¡¨ç¤ºæ¨¡å‹è§£é‡Šæ•°æ®å˜å¼‚çš„èƒ½åŠ›\")\n",
    "print()\n",
    "\n",
    "# æ‰“å°å¯¹æ¯”è¡¨æ ¼\n",
    "comparison_data = []\n",
    "for model_name, metrics in results_summary.items():\n",
    "    if metrics is not None:\n",
    "        comparison_data.append({\n",
    "            \"æ¨¡å‹\": model_name,\n",
    "            \"RMSE\": f\"{metrics['rmse']:.4f}\",\n",
    "            \"MAE\": f\"{metrics['mae']:.4f}\",\n",
    "            \"RÂ²\": f\"{metrics['r2']:.4f}\"\n",
    "        })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# æ‰¾å‡ºæœ€ä½³æ¨¡å‹\n",
    "best_model = max(results_summary.items(), key=lambda x: x[1]['r2'] if x[1] is not None else 0)\n",
    "print(f\"\\nğŸ† æœ€ä½³æ¨¡å‹: {best_model[0]}\")\n",
    "print(f\"   RÂ² = {best_model[1]['r2']:.4f} (èƒ½è§£é‡Š{best_model[1]['r2']*100:.1f}%çš„æ•°æ®å˜å¼‚)\")\n",
    "print(f\"   RMSE = {best_model[1]['rmse']:.4f} (å¹³å‡é¢„æµ‹è¯¯å·®)\")\n",
    "print(f\"   MAE = {best_model[1]['mae']:.4f} (å¹³å‡ç»å¯¹è¯¯å·®)\")\n",
    "\n",
    "# ä¿å­˜ä¸ºCSV\n",
    "rows = []\n",
    "for k,v in results_summary.items():\n",
    "    if v is None:\n",
    "        continue\n",
    "    rows.append({\"model\": k, \"rmse\": v[\"rmse\"], \"mae\": v[\"mae\"], \"r2\": v[\"r2\"]})\n",
    "pd.DataFrame(rows).to_csv(\"results/metrics/model_comparison.csv\", index=False)\n",
    "print(\"\\nå·²ä¿å­˜ model_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3392254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æµç¨‹å®Œæˆã€‚æ£€æŸ¥ results/ ä¸‹çš„è¾“å‡ºæ–‡ä»¶å¹¶ä¸Šä¼ è‡³ GitHubã€‚\n"
     ]
    }
   ],
   "source": [
    "# ---------- 12. ç®€å•çš„æ®‹å·®ç›´æ–¹å›¾ï¼ˆä»¥æœ€ä½³ RF ä¸ºä¾‹ï¼‰ ----------\n",
    "residuals = y_test - y_pred_best_rf\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(residuals, bins=30)\n",
    "plt.xlabel(\"residual\")\n",
    "plt.title(\"Residuals histogram (best RF)\")\n",
    "plt.savefig(\"results/figures/residuals_best_rf.png\", bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"æµç¨‹å®Œæˆã€‚æ£€æŸ¥ results/ ä¸‹çš„è¾“å‡ºæ–‡ä»¶å¹¶ä¸Šä¼ è‡³ GitHubã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2eef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 13. æ¨¡å‹æ€§èƒ½å¯è§†åŒ–åˆ†æ ----------\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹æ€§èƒ½å¯¹æ¯”å›¾\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. RMSEå¯¹æ¯”\n",
    "models = ['LinearRegression', 'RandomForest', 'XGBoost']\n",
    "rmse_values = [metrics_lr['rmse'], metrics_rf['rmse'], metrics_xgb['rmse']]\n",
    "axes[0,0].bar(models, rmse_values, color=['skyblue', 'lightgreen', 'lightcoral'])\n",
    "axes[0,0].set_title('RMSEå¯¹æ¯” (è¶Šå°è¶Šå¥½)', fontsize=14)\n",
    "axes[0,0].set_ylabel('RMSE')\n",
    "for i, v in enumerate(rmse_values):\n",
    "    axes[0,0].text(i, v + 0.01, f'{v:.4f}', ha='center', va='bottom')\n",
    "\n",
    "# 2. MAEå¯¹æ¯”\n",
    "mae_values = [metrics_lr['mae'], metrics_rf['mae'], metrics_xgb['mae']]\n",
    "axes[0,1].bar(models, mae_values, color=['skyblue', 'lightgreen', 'lightcoral'])\n",
    "axes[0,1].set_title('MAEå¯¹æ¯” (è¶Šå°è¶Šå¥½)', fontsize=14)\n",
    "axes[0,1].set_ylabel('MAE')\n",
    "for i, v in enumerate(mae_values):\n",
    "    axes[0,1].text(i, v + 0.01, f'{v:.4f}', ha='center', va='bottom')\n",
    "\n",
    "# 3. RÂ²å¯¹æ¯”\n",
    "r2_values = [metrics_lr['r2'], metrics_rf['r2'], metrics_xgb['r2']]\n",
    "axes[1,0].bar(models, r2_values, color=['skyblue', 'lightgreen', 'lightcoral'])\n",
    "axes[1,0].set_title('RÂ²å¯¹æ¯” (è¶Šæ¥è¿‘1è¶Šå¥½)', fontsize=14)\n",
    "axes[1,0].set_ylabel('RÂ²')\n",
    "axes[1,0].set_ylim(0, 1)\n",
    "for i, v in enumerate(r2_values):\n",
    "    axes[1,0].text(i, v + 0.02, f'{v:.4f}', ha='center', va='bottom')\n",
    "\n",
    "# 4. ç»¼åˆæ€§èƒ½é›·è¾¾å›¾\n",
    "from math import pi\n",
    "categories = ['RMSE\\n(åå‘)', 'MAE\\n(åå‘)', 'RÂ²\\n(æ­£å‘)']\n",
    "N = len(categories)\n",
    "\n",
    "# æ ‡å‡†åŒ–æ•°æ® (RMSEå’ŒMAEè¶Šå°è¶Šå¥½ï¼Œæ‰€ä»¥ç”¨1-æ ‡å‡†åŒ–å€¼)\n",
    "rmse_norm = [1 - (v - min(rmse_values)) / (max(rmse_values) - min(rmse_values)) for v in rmse_values]\n",
    "mae_norm = [1 - (v - min(mae_values)) / (max(mae_values) - min(mae_values)) for v in mae_values]\n",
    "r2_norm = r2_values\n",
    "\n",
    "angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    "\n",
    "# ç»˜åˆ¶æ¯ä¸ªæ¨¡å‹çš„é›·è¾¾å›¾\n",
    "colors = ['skyblue', 'lightgreen', 'lightcoral']\n",
    "for i, model in enumerate(models):\n",
    "    values = [rmse_norm[i], mae_norm[i], r2_norm[i]]\n",
    "    values += values[:1]\n",
    "    \n",
    "    axes[1,1].plot(angles, values, 'o-', linewidth=2, label=model, color=colors[i])\n",
    "    axes[1,1].fill(angles, values, alpha=0.25, color=colors[i])\n",
    "\n",
    "axes[1,1].set_xticks(angles[:-1])\n",
    "axes[1,1].set_xticklabels(categories)\n",
    "axes[1,1].set_ylim(0, 1)\n",
    "axes[1,1].set_title('ç»¼åˆæ€§èƒ½é›·è¾¾å›¾', fontsize=14)\n",
    "axes[1,1].legend()\n",
    "axes[1,1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"results/figures/model_performance_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"æ¨¡å‹æ€§èƒ½å¯¹æ¯”å›¾å·²ä¿å­˜ä¸º results/figures/model_performance_comparison.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c1a1bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
